{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "405c5b6f",
   "metadata": {},
   "source": [
    "## 10. Beautiful Soup\n",
    "- HTML과 XML 파일에서 데이터를 추출하기 위한 라이브러리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d34e2129",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ab0c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a></a>\n",
      "<html><body><a></a></body></html>\n"
     ]
    }
   ],
   "source": [
    "with open(\"test.html\", \"r\", encoding=\"utf-8\") as f:\n",
    "    html_data = f.read()\n",
    "\n",
    "# soup 객체 생성\n",
    "# soup = BeautifulSoup(html_data, \"html.parser\") # 내장 파서\n",
    "soup = BeautifulSoup(html_data, \"lxml\") # xml 일때 사용, 설치 필요\n",
    "# print(soup)\n",
    "print(soup.prettify()) # 들여쓰기 표시\n",
    "# 파서 차이비교\n",
    "print(BeautifulSoup(\"<a></p>\", \"html.parser\")) # <a></a>\n",
    "print(BeautifulSoup(\"<a></p>\", \"lxml\")) # <html><body><a></a></body></html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46355601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1 class=\"title\">Hello BeautifulSoup</h1>\n",
      "Hello BeautifulSoup\n",
      "Hello BeautifulSoup\n"
     ]
    }
   ],
   "source": [
    "# 데이터 선택\n",
    "# find() - 첫 번째 매칭 요소 선택\n",
    "# 1) 태그를 기준으로 탐색\n",
    "title_tag = soup.find(\"h1\")\n",
    "print(title_tag)\n",
    "print(title_tag.text)\n",
    "print(title_tag.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "331dec27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕! 아름다운 수프\n"
     ]
    }
   ],
   "source": [
    "# find() = 속성 조건으로 검색 가능\n",
    "result = soup.find(\"h1\", class_=\"sub_title\")\n",
    "print(result.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23ff78b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<h1 class=\"title\">Hello BeautifulSoup</h1>, <h1 class=\"sub_title\">안녕! 아름다운 수프</h1>]\n",
      "Hello BeautifulSoup\n",
      "안녕! 아름다운 수프\n"
     ]
    }
   ],
   "source": [
    "# find_all = 모든 매칭된 요소를 선택\n",
    "result = soup.find_all(\"h1\")\n",
    "print(result)\n",
    "\n",
    "for i in result:\n",
    "    print(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e50c5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<ul class=\"items\">\n",
      "<li>사과</li>\n",
      "<li>바나나</li>\n",
      "<li>체리</li>\n",
      "</ul>, <ul class=\"items\">\n",
      "<li>Python</li>\n",
      "<li>C++</li>\n",
      "<li>SQL</li>\n",
      "</ul>]\n",
      "\n",
      "사과\n",
      "바나나\n",
      "체리\n",
      "\n",
      "\n",
      "Python\n",
      "C++\n",
      "SQL\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# select() - 모든 매칭 요소 선택\n",
    "# css 선택자로 선택\n",
    "result = soup.select(\"ul.items\")\n",
    "print(result)\n",
    "\n",
    "for i in result:\n",
    "    print(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dee36894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ul class=\"items\">\n",
       "<li>사과</li>\n",
       "<li>바나나</li>\n",
       "<li>체리</li>\n",
       "</ul>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select_one() - 첫 번째 매칭 요소 선택\n",
    "result = soup.select_one(\"ul.items\")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737444e9",
   "metadata": {},
   "source": [
    "### Requests\n",
    "- HTTP 프로토콜을 이용하여 웹 사이트로부터 데이터를 송수신하는 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1fb9159a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.Good Goodbye\n",
      "2.ONE MORE TIME\n",
      "3.타임캡슐\n",
      "4.Blue Valentine\n",
      "5.SPAGHETTI (feat. j-hope of BTS)\n",
      "6.Golden\n",
      "7.Drowning\n",
      "8.멸종위기사랑\n",
      "9.첫 눈\n",
      "10.달리 표현할 수 없어요\n"
     ]
    }
   ],
   "source": [
    "# BeautifulSoup & requests 함께 이용\n",
    "# 멜론에서 Top10의 노래 제목을 받아오기\n",
    "\n",
    "url = \"https://www.melon.com/chart/index.htm\"\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "# print(response.status_code) # 200: 성공, 404: 페이지 없음, 500: 서버 에러\n",
    "# print(response.text)\n",
    "\n",
    "soup = BeautifulSoup(response.text, \"lxml\")\n",
    "\n",
    "songs = soup.select(\"div.ellipsis.rank01 a\")[:10]\n",
    "\n",
    "for idx, song in enumerate(songs):\n",
    "    print(f\"{idx + 1}.{song.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9999442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- ‘대장동 항소포기 반발’ 김창진·박현철 검사장, 좌천에 사의 표명\n",
      ",https://n.news.naver.com/mnews/article/016/0002570888\n",
      "\n",
      "- 서울지하철 1노조 파업 철회…임단협 결렬 후 극적 타결\n",
      ",https://n.news.naver.com/mnews/article/055/0001315563\n",
      "\n",
      "- 총리 직속 의료혁신위 첫 회의…“내년 3월까지 의제 확정”\n",
      ",https://n.news.naver.com/mnews/article/056/0012083950\n",
      "\n",
      "- 고양시, ‘2025 청소년정책 우수 지자체’ 국무총리 표창 수상\n",
      ",https://n.news.naver.com/mnews/article/021/0002756305\n",
      "\n",
      "- 강제동원 피해자, 일본제철 상대 손배소 또 승소 확정\n",
      ",https://n.news.naver.com/mnews/article/056/0012083842\n",
      "\n",
      "- 특검, 한덕수·최상목 임명권 자의적 행사 ‘윤 탄핵심판 방해’로 규정\n",
      ",https://n.news.naver.com/mnews/article/028/0002781055\n",
      "\n",
      "- 한강버스 규정 위반 28건 등 120건 지적…市 \"이달 중 75건 조치\"\n",
      ",https://n.news.naver.com/mnews/article/011/0004566276\n",
      "\n",
      "- 통일교 대국민 사과... “윤영호의 개인 일탈” 선 긋기\n",
      ",https://n.news.naver.com/mnews/article/023/0003946434\n",
      "\n",
      "- 광주대표도서관 붕괴사고 희생자 2명 빈소 차려져\n",
      ",https://n.news.naver.com/mnews/article/055/0001315535\n",
      "\n",
      "- 경찰, '통일교 금품' 수사 착수‥윤영호 구치소 접견\n",
      ",https://n.news.naver.com/mnews/article/214/0001467479\n",
      "\n",
      "- \"에티켓 지켜라\"…'노조 조끼' 입은 손 제지한 백화점 [소셜픽]\n",
      ",https://n.news.naver.com/mnews/article/437/0000468489\n",
      "\n",
      "- 광주대표도서관 공사장 붕괴…밤샘 수색에도 매몰자 2명 못찾아\n",
      ",https://n.news.naver.com/mnews/article/022/0004089639\n",
      "\n",
      "- 의성·칠곡·예천·봉화서 교통사고로 1명 사망·3명 중경상\n",
      ",https://n.news.naver.com/mnews/article/421/0008657087\n",
      "\n",
      "- [단독] '배드파더' 김동성 측근의 폭로 \"월 600 이상 벌며 자녀 해외유학까지 보냈다\"\n",
      ",https://n.news.naver.com/mnews/article/002/0002418489\n",
      "\n",
      "- 앞으로 노동절에 쉬나…李대통령 \"공무원만 출근\"\n",
      ",https://n.news.naver.com/mnews/article/015/0005223555\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "url = \"https://news.naver.com/section/102\"\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(response.text, \"lxml\")\n",
    "\n",
    "articles = soup.select(\"div.sa_item_flex a.sa_text_title\")\n",
    "\n",
    "for a in articles[:15]:\n",
    "    title = a.get_text(strip=True)\n",
    "    href = a.get(\"href\")\n",
    "\n",
    "  \n",
    "    if href.startswith(\"/\"):\n",
    "        link = \"https://news.naver.com\" + href\n",
    "    else:\n",
    "        link = href\n",
    "\n",
    "    print(f\"- {title}\\n,{link}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2665428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==오늘의 뉴스==\n",
      "김병기 원내대표, 쿠팡 박대준 대표와 국감 전 호텔서 식사 논란 / 링크: https://imnews.imbc.com/news/2025/politics/article/6784148_36711.html\n",
      "[2보] '개인정보 유출' 박대준 쿠팡 대표 사임…사실상 경질 / 링크: https://www.yna.co.kr/view/AKR20251210108451030?input=1195m\n",
      "김범석 '복심' 쿠팡 대표로…쿠팡Inc. 사태 직접 책임 의지(종합) / 링크: https://www.news1.kr/industry/distribution/6004224\n",
      "쿠팡 이용자 수, 유출 사태 9일 만에 ‘이전 수준’ 복귀 / 링크: https://biz.chosun.com/distribution/channel/2025/12/11/CWFC2TYGMBCQZA3OC46HNXR4QM/?utm_source=naver&utm_medium=original&utm_campaign=biz\n"
     ]
    }
   ],
   "source": [
    "# 웹 크롤링 Leader\n",
    "word = input(\"검색어를 입력하세요: \")\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\" : \"Mozilla/5.0\"\n",
    "}\n",
    "\n",
    "response = requests.get(f\"https://search.naver.com/search.naver?query={word}\", headers=headers)\n",
    "soup = BeautifulSoup(response.text, \"lxml\")\n",
    "# print(soup.prettify())\n",
    "news_list = soup.select(\"a.fender-ui_228e3bd1.moM44hE6Je7O8nL1iBI9\")\n",
    "print(\"==오늘의 뉴스==\")\n",
    "\n",
    "for a in news_list:\n",
    "    print(f\"{a.get_text()} / 링크: {a.get(\"href\")}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38288a2",
   "metadata": {},
   "source": [
    "### openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a98967a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크롤링한 자료를 엑셀로 저장\n",
    "import openpyxl\n",
    "\n",
    "# 엑셀 파일 만들기\n",
    "wb = openpyxl.Workbook()\n",
    "\n",
    "# 시트 만들기\n",
    "ws = wb.create_sheet(\"test\")\n",
    "\n",
    "ws[\"A1\"] = \"이름\"\n",
    "ws[\"B1\"] = \"나이\"\n",
    "\n",
    "ws[\"A2\"] = \"홍길동\"\n",
    "ws[\"B2\"] = 30\n",
    "\n",
    "wb.save(\"test.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "807cf98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 불러오기\n",
    "wb = openpyxl.load_workbook(\"test.xlsx\")\n",
    "\n",
    "# 시트 선택\n",
    "ws = wb[\"test\"]\n",
    "\n",
    "# 여러 자료 추가\n",
    "data = [\n",
    "    [\"kim\", 20],\n",
    "    [\"lee\", 14],\n",
    "    [\"park\", 34]\n",
    "]\n",
    "\n",
    "for row in data:\n",
    "    ws.append(row)\n",
    "\n",
    "wb.save(\"test.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f8d2e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "환율 정보\n",
      "미국 USD 1,473.40\n",
      "유럽연합 EUR 1,729.77\n",
      "일본 JPY (100엔) 946.16\n",
      "중국 CNY 208.94\n",
      "홍콩 HKD 189.35\n",
      "\n",
      "엑셀 저장완료->환율정보.xlsx\n"
     ]
    }
   ],
   "source": [
    "# 실습\n",
    "url = \"https://finance.naver.com/marketindex/exchangeList.naver\"\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0\"\n",
    "}\n",
    "\n",
    "res = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(res.text, \"lxml\")\n",
    "rows = soup.select(\"table.tbl_exchange tbody tr\")\n",
    "currency = []\n",
    "rate = []\n",
    "data = []\n",
    "for row in rows:\n",
    "    name = row.select_one(\"td.tit a\").text.strip()\n",
    "    value = row.select_one(\"td.sale\").text.strip()\n",
    "\n",
    "    if (\"USD\" in name) or (\"JPY\" in name) or (\"EUR\" in name) or (\"CNY\" in name) or (\"HKD\" in name):\n",
    "        data.append({\"통화\": name, \"환율\": value})\n",
    "\n",
    "print(\"환율 정보\")\n",
    "for item in data:\n",
    "    print(item[\"통화\"], item[\"환율\"])\n",
    "\n",
    "wb = openpyxl.Workbook()\n",
    "ws = wb.active\n",
    "ws.title = \"환율 정보\"\n",
    "ws.append([\"통화\",\"환율\"])\n",
    "\n",
    "for item in data:\n",
    "    ws.append([item[\"통화\"], item[\"환율\"]])\n",
    "wb.save(\"환율정보.xlsx\")\n",
    "print(\"\\n엑셀 저장완료->환율정보.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "49b07b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실습 3 leader\n",
    "res = requests.get(\"https://finance.naver.com/marketindex/\")\n",
    "soup = BeautifulSoup(res.text, \"lxml\")\n",
    "result = soup.select(\"div.market1 a.head\")\n",
    "wb = openpyxl.load_workbook(\"test.xlsx\")\n",
    "ws = wb[\"test\"]\n",
    "# data = []\n",
    "ws.append([\"통화\", \"환율\"])\n",
    "for a in result:\n",
    "    exchange = a.select_one(\"span.blind\").get_text().split()[1]\n",
    "    value = a.select_one(\"span.value\").get_text()\n",
    " #   data.append([exchange, value])\n",
    "    ws.append([exchange, value])\n",
    "wb.save(\"test.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96bb6a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
